{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "import playsound\n",
    "from threading import Thread\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     main()\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m ret, frame \u001b[39m=\u001b[39m video_capture\u001b[39m.\u001b[39mread(\u001b[39m0\u001b[39m)   \u001b[39m#reading video capture\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# get it into the correct format\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m#small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m#frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[39m# get the correct face landmarks\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m face_landmarks_list \u001b[39m=\u001b[39m face_recognition\u001b[39m.\u001b[39;49mface_landmarks(frame) \u001b[39m#face recognition module to get face landmarks like eyes,nose,etc..\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# get eyes\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m face_landmark \u001b[39min\u001b[39;00m face_landmarks_list:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py:177\u001b[0m, in \u001b[0;36mface_landmarks\u001b[0;34m(face_image, face_locations, model)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=167'>168</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mface_landmarks\u001b[39m(face_image, face_locations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlarge\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=168'>169</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=169'>170</a>\u001b[0m \u001b[39m    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=170'>171</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=174'>175</a>\u001b[0m \u001b[39m    :return: A list of dicts of face feature locations (eyes, nose, etc)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=175'>176</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=176'>177</a>\u001b[0m     landmarks \u001b[39m=\u001b[39m _raw_face_landmarks(face_image, face_locations, model)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=177'>178</a>\u001b[0m     landmarks_as_tuples \u001b[39m=\u001b[39m [[(p\u001b[39m.\u001b[39mx, p\u001b[39m.\u001b[39my) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m landmark\u001b[39m.\u001b[39mparts()] \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m landmarks]\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=179'>180</a>\u001b[0m     \u001b[39m# For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py:156\u001b[0m, in \u001b[0;36m_raw_face_landmarks\u001b[0;34m(face_image, face_locations, model)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=153'>154</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_face_landmarks\u001b[39m(face_image, face_locations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlarge\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=154'>155</a>\u001b[0m     \u001b[39mif\u001b[39;00m face_locations \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=155'>156</a>\u001b[0m         face_locations \u001b[39m=\u001b[39m _raw_face_locations(face_image)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=156'>157</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=157'>158</a>\u001b[0m         face_locations \u001b[39m=\u001b[39m [_css_to_rect(face_location) \u001b[39mfor\u001b[39;00m face_location \u001b[39min\u001b[39;00m face_locations]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=103'>104</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/test/lib/python3.9/site-packages/face_recognition/api.py?line=104'>105</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m face_detector(img, number_of_times_to_upsample)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MIN_AER = 0.30  #Minimun eye aspect ratio\n",
    "EYE_AR_CONSEC_FRAMES = 10   #After passing this number of frames we will detect.\n",
    "\n",
    "# initialize the frame counter as well as a boolean used to\n",
    "# indicate if the alarm is going off\n",
    "COUNTER = 0 \n",
    "ALARM_ON = False #default alarm is false\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    " # compute the euclidean distances between the two sets of\n",
    " # vertical eye landmarks (x, y)-coordinates\n",
    " A = dist.euclidean(eye[1], eye[5])\n",
    " B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    " # compute the euclidean distance between the horizontal\n",
    " # eye landmark (x, y)-coordinates\n",
    " C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    " # compute the eye aspect ratio\n",
    " ear = (A + B) / (2.0 * C)\n",
    "\n",
    " # return the eye aspect ratio\n",
    " return ear\n",
    "\n",
    "def sound_alarm(alarm_file):\n",
    " # play an alarm sound\n",
    " playsound.playsound(alarm_file)\n",
    " \n",
    "def main():\n",
    "    global COUNTER\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    while True:       \n",
    "        ret, frame = video_capture.read(0)   #reading video capture\n",
    "\n",
    "        # get it into the correct format\n",
    "        #small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # get the correct face landmarks\n",
    "        \n",
    "        face_landmarks_list = face_recognition.face_landmarks(frame) #face recognition module to get face landmarks like eyes,nose,etc..\n",
    "\n",
    "            # get eyes\n",
    "        for face_landmark in face_landmarks_list:\n",
    "                        leftEye = face_landmark['left_eye']\n",
    "                        rightEye = face_landmark['right_eye']\n",
    "                        #eye aspect ratio for left and right eyes\n",
    "                        leftEAR = eye_aspect_ratio(leftEye)\n",
    "                        rightEAR = eye_aspect_ratio(rightEye)\n",
    "                        # average the eye aspect ratio together for both eyes\n",
    "                        ear = (leftEAR + rightEAR) / 2\n",
    "                        #========================converting left and right eye values in numpy arrays\n",
    "                        lpts = np.array(leftEye)\n",
    "                        rpts = np.array(rightEye)\n",
    "                        #==================showing line from left of left eye and right of right eye\n",
    "                        cv2.polylines(frame, [lpts],True ,(255,255,0), 1)\n",
    "                        cv2.polylines(frame, [rpts],True ,(255,255,0), 1)\n",
    "                        \n",
    "                        # check to see if the eye aspect ratio is below the blink\n",
    "                        # threshold, and if so, increment the blink frame counter\n",
    "                        if ear < MIN_AER:\n",
    "                                COUNTER+= 1\n",
    "\n",
    "                                # if the eyes were closed for a sufficient number of times\n",
    "                                # then sound the alarm\n",
    "                                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                                        # if the alarm is not on, turn it on\n",
    "                                        if not ALARM_ON:\n",
    "                                                ALARM_ON = True\n",
    "                                                t = Thread(target=sound_alarm,\n",
    "                                                                args=('//Users/dhruvdasadia/Documents/IBM Project /Phase-2/Code/alarm.wav',))\n",
    "                                                t.deamon = True  #The Daemon Thread does not block the main thread from exiting and continues to run in the background\n",
    "                                                t.start()\n",
    "\n",
    "                                        # draw an alarm on the frame\n",
    "                                        cv2.putText(frame, \"ALERT! You are feeling asleep!\", (10, 30),\n",
    "                                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                        # otherwise, the eye aspect ratio is not below the blink\n",
    "                        # threshold, so reset the counter and alarm\n",
    "                        else:\n",
    "                                COUNTER = 0\n",
    "                                ALARM_ON = False\n",
    "\n",
    "                        # draw the computed eye aspect ratio on the frame to help\n",
    "                        # with debugging and setting the correct eye aspect ratio\n",
    "                        # thresholds and frame counters\n",
    "                        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (500, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    " \n",
    "                        # show the frame\n",
    "                        cv2.imshow(\"Sleep detection program.\", frame)\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    # do a bit of cleanup\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
